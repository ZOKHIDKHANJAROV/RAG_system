import requests
import numpy as np
import faiss
import sys
import os

# =========================
# ‚öôÔ∏è –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# =========================
OLLAMA_URL = "http://localhost:11434"
EMBED_MODEL = "nomic-embed-text"
GEN_MODEL = "mistral"
CHUNK_SIZE = 500  # –°–∏–º–≤–æ–ª–æ–≤ (–ø—Ä–∏–º–µ—Ä–Ω–æ)
OVERLAP = 50      # –°–∏–º–≤–æ–ª–æ–≤ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è
DOC_PATH = "document.txt"
# –ü–æ—Ä–æ–≥ –¥–∏—Å—Ç–∞–Ω—Ü–∏–∏ (–¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤: 0=–∏–¥–µ–Ω—Ç–∏—á–Ω—ã, 2=–ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—ã)
# –î–ª—è nomic-embed-text —Ö–æ—Ä–æ—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –æ–∫–æ–ª–æ 0.8 - 1.2 –¥–ª—è L2 –Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
MAX_DISTANCE_THRESHOLD = 1.2 

session = requests.Session()

# =========================
# üß© –£–ú–ù–´–ô –ß–ê–ù–ö–ò–ù–ì
# =========================
def chunk_text_smart(text, chunk_size=300, overlap=50):
    """
    –î–µ–ª–∏—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏, —Å—Ç–∞—Ä–∞—è—Å—å –Ω–µ —Ä–∞–∑—Ä—ã–≤–∞—Ç—å —Å–ª–æ–≤–∞.
    """
    if not text:
        return []
    
    words = text.split()
    chunks = []
    current_chunk = []
    current_length = 0
    
    # –ü—Ä–æ—Å—Ç–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Å–ª–æ–≤
    for word in words:
        word_len = len(word) + 1 # +1 –¥–ª—è –ø—Ä–æ–±–µ–ª–∞
        if current_length + word_len > chunk_size and current_chunk:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π —á–∞–Ω–∫
            full_chunk = " ".join(current_chunk)
            chunks.append(full_chunk)
            
            # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è overlap: –æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–ª–æ–≤, —á—Ç–æ–±—ã –≤–ª–µ–∑–ª–∏ –≤ overlap
            # –≠—Ç–æ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞, –Ω–æ –æ–Ω–∞ –ª—É—á—à–µ –ø—Ä–æ—Å—Ç–æ–≥–æ —Å—Ä–µ–∑–∞
            overlap_len = 0
            new_chunk = []
            for w in reversed(current_chunk):
                if overlap_len + len(w) < overlap:
                    new_chunk.insert(0, w)
                    overlap_len += len(w) + 1
                else:
                    break
            
            current_chunk = new_chunk
            current_length = overlap_len

        current_chunk.append(word)
        current_length += word_len

    if current_chunk:
        chunks.append(" ".join(current_chunk))

    return chunks

# =========================
# üß† EMBEDDINGS (Batch support if possible, or fast loop)
# =========================
def get_embeddings(texts):
    embeddings = []
    print(f"‚è≥ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤...", end="", flush=True)
    
    for i, text in enumerate(texts):
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º session –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
            response = session.post(
                f"{OLLAMA_URL}/api/embeddings",
                json={
                    "model": EMBED_MODEL,
                    "prompt": text
                },
                timeout=60
            )
            response.raise_for_status()
            emb = response.json()["embedding"]
            embeddings.append(emb)
        except Exception as e:
            print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ (index {i}): {e}")
            sys.exit(1)
            
    print(" –ì–æ—Ç–æ–≤–æ!")
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy array –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
    mat = np.array(embeddings, dtype="float32")
    faiss.normalize_L2(mat) # <--- –í–ê–ñ–ù–û: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    return mat

# =========================
# üß† GENERATION
# =========================
def ollama_generate(prompt):
    try:
        response = session.post(
            f"{OLLAMA_URL}/api/generate",
            json={
                "model": GEN_MODEL,
                "prompt": prompt,
                "stream": False
            },
            timeout=120
        )
        response.raise_for_status()
        return response.json()["response"]
    except requests.RequestException as e:
        return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}"

# =========================
# üöÄ MAIN PIPELINE
# =========================
def main():
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞
    if not os.path.exists(DOC_PATH):
        print(f"‚ùå –§–∞–π–ª {DOC_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        sys.exit(1)

    with open(DOC_PATH, "r", encoding="utf-8") as f:
        document_text = f.read()

    if not document_text.strip():
        print("‚ùå –§–∞–π–ª –ø—É—Å—Ç.")
        sys.exit(1)

    # 2. –ß–∞–Ω–∫–∏–Ω–≥
    text_chunks = chunk_text_smart(document_text, CHUNK_SIZE, OVERLAP)
    
    chunks_meta = [
        {"id": i, "text": txt, "source": DOC_PATH}
        for i, txt in enumerate(text_chunks)
    ]
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks_meta)}")

    # 3. –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
    doc_embeddings = get_embeddings([c["text"] for c in chunks_meta])

    # 4. FAISS Index
    dimension = doc_embeddings.shape[1]
    index = faiss.IndexFlatL2(dimension) # L2 –Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–∞—Ö = Cosine
    index.add(doc_embeddings)

    # 5. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤
    while True:
        print("\n" + "="*40)
        question = input("–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å (–∏–ª–∏ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞): ").strip()
        if question.lower() in ['q', 'exit', 'quit']:
            break
        if not question:
            continue

        # –≠–º–±–µ–¥–¥–∏–Ω–≥ –≤–æ–ø—Ä–æ—Å–∞ (—Ç–æ–∂–µ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º!)
        q_emb = get_embeddings([question]) # –í–µ—Ä–Ω–µ—Ç —É–∂–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä
        
        # –ü–æ–∏—Å–∫
        TOP_K = 3
        distances, indices = index.search(q_emb, TOP_K)
        
        best_distance = distances[0][0]
        print(f"üîé –õ—É—á—à–∞—è –¥–∏—Å—Ç–∞–Ω—Ü–∏—è (L2): {best_distance:.4f}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ä–æ–≥–∞
        # –ü—Ä–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: –î–∏—Å—Ç–∞–Ω—Ü–∏—è 0 = —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, 2 = –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω–æ—Å—Ç—å.
        # –û–±—ã—á–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–µ < 1.0 (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –º–æ–¥–µ–ª–∏)
        if best_distance > MAX_DISTANCE_THRESHOLD:
            print("\n‚ö†Ô∏è  –û—Ç–≤–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ (–¥–∏—Å—Ç–∞–Ω—Ü–∏—è —Å–ª–∏—à–∫–æ–º –≤–µ–ª–∏–∫–∞).")
            # –ú–æ–∂–Ω–æ –≤—Å–µ —Ä–∞–≤–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç–∏—Ç—å, –Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–¥–∏—Ç—å
            # continue 
        
        selected_chunks = [chunks_meta[i] for i in indices[0]]
        context_text = "\n---\n".join(c["text"] for c in selected_chunks)

        # –ü—Ä–æ–º–ø—Ç
        prompt = f"""
–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –æ—Ç–≤–µ—á–∞—é—â–∏–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.
–ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞. 
–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –æ—Ç–≤–µ—Ç—å "–Ø –Ω–µ –∑–Ω–∞—é –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞".
–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã.

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context_text}

–í–æ–ø—Ä–æ—Å: 
{question}
"""
        print("ü§î –î—É–º–∞—é...")
        answer = ollama_generate(prompt)
        
        print(f"\nüß† –û—Ç–≤–µ—Ç:\n{answer.strip()}")
        print("\nüìö –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã:")
        for idx, chunk in enumerate(selected_chunks):
            print(f"[{idx+1}] ID:{chunk['id']} (Dist: {distances[0][idx]:.3f}) -> {chunk['text'][:50]}...")

if __name__ == "__main__":
    main()